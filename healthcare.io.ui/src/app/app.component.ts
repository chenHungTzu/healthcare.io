import { Component, ElementRef, ViewChild } from '@angular/core';
import { environment } from '../environments/environment';
import { CognitoIdentityClient, GetIdCommand, GetOpenIdTokenCommand } from '@aws-sdk/client-cognito-identity';
import { STSClient, AssumeRoleWithWebIdentityCommand } from '@aws-sdk/client-sts';
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";
import { KinesisVideoClient, GetSignalingChannelEndpointCommand } from '@aws-sdk/client-kinesis-video';
import { KinesisVideoSignalingClient, GetIceServerConfigCommand } from '@aws-sdk/client-kinesis-video-signaling';
import { TranscribeStreamingClient, StartStreamTranscriptionCommand, AudioStream } from '@aws-sdk/client-transcribe-streaming';
import { Role } from './kvsRole';
import { AwsConfig } from './aws.config';
import { HttpClient, HttpClientModule } from '@angular/common/http';
import { DatePipe } from '@angular/common';
import { FormsModule } from '@angular/forms';
import { ChatMessage } from './chatMessage';

const KVSWebRTC = (window as any).KVSWebRTC;

@Component({
  selector: 'app-root',
  standalone: true,
  imports: [DatePipe, FormsModule, HttpClientModule],
  templateUrl: './app.component.html',
  styleUrl: './app.component.scss'
})
export class AppComponent {
  @ViewChild("remoteView", { static: true }) remoteView: ElementRef = new ElementRef(null);
  @ViewChild("localView", { static: true }) localView: ElementRef = new ElementRef(null);

  localStream!: MediaStream;
  remoteStream!: MediaStream;
  mediaRecorder!: MediaRecorder;
  recordedChunks: Blob[] = [];

  // æ–°å¢å³æ™‚è½‰éŒ„ç›¸é—œå±¬æ€§
  audioContext!: AudioContext;
  analyser!: AnalyserNode;
  transcribeClient!: TranscribeStreamingClient;
  isTranscribing = false;
  transcriptionText = '';
  soundDetectionActive = false;
  isTranscribeStreamActive = false;
  currentTranscribeCommand: any = null;
  transcribeMediaRecorder!: MediaRecorder; // æ›¿æ› audioProcessor
  transcribeStream!: MediaStream; // ç”¨æ–¼è½‰éŒ„çš„éŸ³è¨Šæµ

  mode: 'init' | 'master' | 'viewer' = 'init';
  isRecording = false;
  isUploading = false;
  sessionId = '';
  isChatOpen = false;
  currentMessage = '';
  chatMessages: ChatMessage[] = [];
  isLoadingMessage = false;

  constructor(private http: HttpClient) {
    // åˆå§‹åŒ– sessionId
    this.sessionId = this.generateSessionId();

    // ä¸€é–‹å§‹å°±åˆå§‹åŒ– Transcribe Client
    this.initTranscribeClient();
  }

  private generateSessionId(): string {
    return 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  }

  /**
   * å–å¾— AWS è¨­å®šï¼ˆå‹•æ…‹å–å¾—è‡¨æ™‚æ†‘è­‰ï¼‰
   * @returns
   */
  private async getAwsConfig(): Promise<AwsConfig> {
    // 1. ç”¢ç”Ÿè‡¨æ™‚ID (æœªæˆæ¬Šèº«ä»½)
    const cognitoIdentity = new CognitoIdentityClient({ region: environment.region });
    const identityPoolId = environment.identity_pool_id;
    const getIdRes = await cognitoIdentity.send(new GetIdCommand({ IdentityPoolId: identityPoolId }));
    const identityId = getIdRes.IdentityId!;
    console.log('IdentityId:', identityId);
    // 2. å–å¾— token
    const getTokenRes = await cognitoIdentity.send(new GetOpenIdTokenCommand({ IdentityId: identityId }));
    const openIdToken = getTokenRes.Token!;
    console.log('OpenIdToken:', openIdToken);
    // 3. å–å¾—è‡¨æ™‚æ†‘è­‰
    const sts = new STSClient({ region: environment.region });
    const roleSessionName = Math.floor(Math.random() * 100000).toString().padStart(5, '0');
    const assumeRoleRes = await sts.send(new AssumeRoleWithWebIdentityCommand({
      RoleArn: environment.kvs_role_arn,
      RoleSessionName: roleSessionName,
      WebIdentityToken: openIdToken,
      DurationSeconds: 3600
    }));
    console.log('AssumeRoleWithWebIdentity response:', assumeRoleRes);

    return {
      channelARN: environment.kvs_channel_arn,
      accessKeyId: assumeRoleRes.Credentials?.AccessKeyId || '',
      secretAccessKey: assumeRoleRes.Credentials?.SecretAccessKey || '',
      sessionToken: assumeRoleRes.Credentials?.SessionToken || '',
      region: environment.region
    };
  }

  /**
   * åˆå§‹åŒ– Transcribe Streaming Client
   */
  private async initTranscribeClient() {
    try {
      const cfg = await this.getAwsConfig();
      this.transcribeClient = new TranscribeStreamingClient({
        region: cfg.region,
        credentials: {
          accessKeyId: cfg.accessKeyId,
          secretAccessKey: cfg.secretAccessKey,
          sessionToken: cfg.sessionToken,
        },
      });
      console.log('Transcribe Client å·²åˆå§‹åŒ–');
    } catch (error) {
      console.error('åˆå§‹åŒ– Transcribe Client å¤±æ•—:', error);
    }
  }

  /**
   * é–‹å§‹å³æ™‚è½‰éŒ„ï¼ˆåœ¨ RTC é€£ç·šå®Œæˆå¾Œè‡ªå‹•èª¿ç”¨ï¼‰
   */
  async startTranscription() {
    if (this.isTranscribing) return;

    try {
      this.isTranscribing = true;

      // å¦‚æœ client é‚„æ²’åˆå§‹åŒ–ï¼Œå†æ¬¡å˜—è©¦åˆå§‹åŒ–
      if (!this.transcribeClient) {
        await this.initTranscribeClient();
      }

      // åˆå§‹åŒ–éŸ³è¨Šåˆ†æå’Œåˆä½µ
      this.audioContext = new AudioContext({ sampleRate: 16000 });
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 512;

      // å‰µå»ºéŸ³è¨Šåˆä½µæµ
      this.transcribeStream = await this.createCombinedAudioStream();

      const source = this.audioContext.createMediaStreamSource(this.transcribeStream);
      source.connect(this.analyser);

      // é–‹å§‹è²éŸ³æª¢æ¸¬ï¼Œåªåœ¨æœ‰è²éŸ³æ™‚å•Ÿå‹•è½‰éŒ„
      this.startSoundDetection();

      console.log('è½‰éŒ„ç³»çµ±å·²æº–å‚™å°±ç·’ï¼Œç­‰å¾…è²éŸ³è§¸ç™¼');

    } catch (error) {
      console.error('å•Ÿå‹•è½‰éŒ„ç³»çµ±å¤±æ•—:', error);
      this.isTranscribing = false;
    }
  }

  /**
   * å‰µå»ºåˆä½µçš„éŸ³è¨Šæµï¼ˆæœ¬åœ° + é ç«¯ï¼‰- ç°¡åŒ–ç‰ˆæœ¬
   */
  private async createCombinedAudioStream(): Promise<MediaStream> {
    const audioContext = new AudioContext({ sampleRate: 16000 });
    const destination = audioContext.createMediaStreamDestination();

    // åˆä½µæœ¬åœ°éŸ³è¨Š
    if (this.localStream && this.localStream.getAudioTracks().length > 0) {
      const localSource = audioContext.createMediaStreamSource(this.localStream);
      localSource.connect(destination);
      console.log('å·²åŠ å…¥æœ¬åœ°éŸ³è¨Šåˆ°è½‰éŒ„æµ');
    }

    // åˆä½µé ç«¯éŸ³è¨Š
    if (this.remoteStream && this.remoteStream.getAudioTracks().length > 0) {
      const remoteSource = audioContext.createMediaStreamSource(this.remoteStream);
      remoteSource.connect(destination);
      console.log('å·²åŠ å…¥é ç«¯éŸ³è¨Šåˆ°è½‰éŒ„æµ');
    } else {
      console.log('é ç«¯éŸ³è¨Šæµå°šæœªå¯ç”¨ï¼Œåƒ…ä½¿ç”¨æœ¬åœ°éŸ³è¨Š');
    }

    return destination.stream;
  }

  /**
   * é–‹å§‹ Transcribe ä¸²æµ - æ”¹ç”¨ PCM æ ¼å¼
   */
  private async startTranscriptionStream() {
    if (this.isTranscribeStreamActive || !this.transcribeStream) return;

    try {
      this.isTranscribeStreamActive = true;
      console.log('é–‹å§‹ Transcribe ä¸²æµ');

      const audioStream = this.createAudioStream();

      const command = new StartStreamTranscriptionCommand({
        LanguageCode: 'zh-TW',
        MediaSampleRateHertz: 16000,
        MediaEncoding: 'pcm', // æ”¹ç”¨ PCM æ ¼å¼
        AudioStream: audioStream,
      });

      const response = await this.transcribeClient.send(command);
      console.log('Transcribe ä¸²æµå·²å»ºç«‹ï¼Œä½¿ç”¨ PCM æ ¼å¼');

      if (response.TranscriptResultStream) {
        for await (const event of response.TranscriptResultStream) {
          if (!this.isTranscribeStreamActive) break;

          if (event.TranscriptEvent?.Transcript?.Results) {
            for (const result of event.TranscriptEvent.Transcript.Results) {
              if (result.Alternatives && result.Alternatives[0]) {
                const transcript = result.Alternatives[0].Transcript || '';
                const isPartial = !result.IsPartial;

                if (transcript.trim()) {
                  if (isPartial) {
                    this.transcriptionText += transcript + ' ';
                    console.log('âœ… å®Œæ•´è½‰éŒ„:', transcript);
                  } else {
                    //this.transcriptionText = transcript
                    //console.log('ğŸ”„ éƒ¨åˆ†è½‰éŒ„:', transcript);
                  }
                }
              }
            }
          }
        }
      }
    } catch (error) {
      console.error('è½‰éŒ„ä¸²æµéŒ¯èª¤:', error);
      this.isTranscribeStreamActive = false;
    }
  }

  /**
   * å‰µå»ºéŸ³è¨Šä¸²æµ - ç›´æ¥ä½¿ç”¨ PCM æ ¼å¼
   */
  private createAudioStream(): AsyncIterable<AudioStream> {
    if (!this.transcribeStream) {
      throw new Error('éŸ³è¨Šæµæœªåˆå§‹åŒ–');
    }

    let isActive = true;
    const self = this;
    let lastDataTime = Date.now();

    return {
      async *[Symbol.asyncIterator]() {
        try {
          // ç›´æ¥ä½¿ç”¨ Web Audio API è™•ç†éŸ³è¨Šæµ
          const audioContext = new AudioContext({ sampleRate: 16000 });
          const source = audioContext.createMediaStreamSource(self.transcribeStream);
          const processor = audioContext.createScriptProcessor(4096, 1, 1);

          let audioChunks: Float32Array[] = [];

          processor.onaudioprocess = (event) => {
            const inputData = event.inputBuffer.getChannelData(0);
            audioChunks.push(new Float32Array(inputData));
          };

          source.connect(processor);
          processor.connect(audioContext.destination);

          console.log('é–‹å§‹ç›´æ¥ PCM éŸ³è¨Šè™•ç†');

          while (isActive && self.isTranscribeStreamActive) {
            await new Promise(resolve => setTimeout(resolve, 250));

            const currentTime = Date.now();

            if (audioChunks.length > 0) {
              // è™•ç†ç´¯ç©çš„éŸ³è¨Šè³‡æ–™
              const chunk = audioChunks.shift()!;

              try {
                // ç›´æ¥è½‰æ› Float32 åˆ° 16-bit PCM
                const pcmData = self.convertFloat32ToPCM(chunk);

                if (pcmData.length > 16384) {
                  const truncatedData = pcmData.slice(0, 16384);
                  yield {
                    AudioEvent: {
                      AudioChunk: truncatedData
                    }
                  };
                } else {
                  yield {
                    AudioEvent: {
                      AudioChunk: pcmData
                    }
                  };
                }

                lastDataTime = currentTime;
                console.log('å·²ç™¼é€ PCM éŸ³è¨Šè³‡æ–™ï¼Œå¤§å°:', Math.min(pcmData.length, 16384));
              } catch (error) {
                console.error('è™•ç†éŸ³è¨Šå¡ŠéŒ¯èª¤:', error);
              }
            } else {
              // ç™¼é€ PCM æ ¼å¼çš„éœéŸ³è³‡æ–™
              if (currentTime - lastDataTime > 5000) {
                const silencePCM = new Int16Array(256).fill(0);
                yield {
                  AudioEvent: {
                    AudioChunk: new Uint8Array(silencePCM.buffer)
                  }
                };
                lastDataTime = currentTime;
                console.log('ç™¼é€ PCM éœéŸ³è³‡æ–™ä¿æŒé€£ç·š');
              }
            }
          }

          // æ¸…ç†è³‡æº
          processor.disconnect();
          source.disconnect();
          audioContext.close();

        } catch (error) {
          console.error('éŸ³è¨Šä¸²æµéŒ¯èª¤:', error);
        } finally {
          isActive = false;
        }
      }
    };
  }

  /**
   * å°‡ Float32 éŸ³è¨Šè³‡æ–™ç›´æ¥è½‰æ›ç‚º PCM æ ¼å¼
   */
  private convertFloat32ToPCM(float32Data: Float32Array): Uint8Array {
    try {
      // è½‰æ›ç‚º 16-bit PCM
      const pcmData = new Int16Array(float32Data.length);
      for (let i = 0; i < float32Data.length; i++) {
        // å°‡ float32 (-1.0 to 1.0) è½‰æ›ç‚º int16 (-32768 to 32767)
        const sample = Math.max(-1, Math.min(1, float32Data[i]));
        pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
      }

      // è¿”å› PCM è³‡æ–™çš„ Uint8Array è¦–åœ–
      return new Uint8Array(pcmData.buffer);
    } catch (error) {
      console.error('Float32 to PCM è½‰æ›å¤±æ•—:', error);

      // å¦‚æœè½‰æ›å¤±æ•—ï¼Œè¿”å›éœéŸ³è³‡æ–™
      const silenceData = new Int16Array(1024).fill(0);
      return new Uint8Array(silenceData.buffer);
    }
  }

  /**
   * æ›´æ–°è½‰éŒ„æµï¼ˆç•¶é ç«¯éŸ³è¨Šé€£æ¥å¾Œèª¿ç”¨ï¼‰- ç°¡åŒ–ç‰ˆæœ¬
   */
  private async updateTranscribeStream() {
    if (!this.isTranscribing) return;

    try {
      // åœæ­¢ç¾æœ‰è½‰éŒ„
      this.stopTranscriptionStream();

      // ç­‰å¾…ä¸€ä¸‹å†é‡æ–°é–‹å§‹
      setTimeout(async () => {
        if (this.transcribeStream) {
          this.transcribeStream.getTracks().forEach(track => track.stop());
        }

        this.transcribeStream = await this.createCombinedAudioStream();

        if (this.audioContext && this.analyser) {
          const source = this.audioContext.createMediaStreamSource(this.transcribeStream);
          source.connect(this.analyser);
        }

        this.startTranscriptionStream();
        console.log('è½‰éŒ„æµå·²æ›´æ–°');
      }, 2000);

    } catch (error) {
      console.error('æ›´æ–°è½‰éŒ„æµå¤±æ•—:', error);
    }
  }

  /**
   * åœæ­¢ Transcribe ä¸²æµ
   */
  private stopTranscriptionStream() {
    if (!this.isTranscribeStreamActive) return;

    this.isTranscribeStreamActive = false;
    this.currentTranscribeCommand = null;

    if (this.transcribeMediaRecorder && this.transcribeMediaRecorder.state === 'recording') {
      this.transcribeMediaRecorder.stop();
    }

  }

  /**
   * åœæ­¢å³æ™‚è½‰éŒ„
   */
  stopTranscription() {
    this.isTranscribing = false;
    this.soundDetectionActive = false;
    this.stopTranscriptionStream();

    if (this.transcribeStream) {
      this.transcribeStream.getTracks().forEach(track => track.stop());
    }

    if (this.audioContext) {
      this.audioContext.close();
    }

    console.log('å³æ™‚è½‰éŒ„å·²åœæ­¢');
    console.log('å®Œæ•´è½‰éŒ„æ–‡å­—:', this.transcriptionText);
    this.clearTranscription();
  }

  /**
   * æ¸…é™¤è½‰éŒ„æ–‡å­—
   */
  clearTranscription() {
    this.transcriptionText = '';
  }

  /**
   * è²éŸ³æª¢æ¸¬
   */
  private startSoundDetection() {
    if (!this.analyser) return;

    this.soundDetectionActive = true;
    const dataArray = new Uint8Array(this.analyser.fftSize);
    const threshold = 6; // è²éŸ³æª¢æ¸¬é–¾å€¼
    let silenceCounter = 0;
    let soundCounter = 0;
    const silenceThreshold = 120; // ç´„2ç§’çš„éœéŸ³å¾Œåœæ­¢è½‰éŒ„
    const soundThreshold = 1; // éœ€è¦é€£çºŒæª¢æ¸¬åˆ°è²éŸ³3æ¬¡æ‰å•Ÿå‹•

    const detectSound = () => {
      if (!this.soundDetectionActive) return;

      this.analyser.getByteTimeDomainData(dataArray);

      let total = 0;
      for (let i = 0; i < dataArray.length; i++) {
        total += Math.abs(dataArray[i] - 128);
      }

      const average = total / dataArray.length;

      if (average > threshold) {
        soundCounter++;
        silenceCounter = 0;

        // éœ€è¦é€£çºŒæª¢æ¸¬åˆ°è²éŸ³æ‰å•Ÿå‹•è½‰éŒ„
        if (soundCounter >= soundThreshold && !this.isTranscribeStreamActive) {
          console.log("ğŸ¤ é€£çºŒæª¢æ¸¬åˆ°è²éŸ³ - å•Ÿå‹•è½‰éŒ„");
          this.startTranscriptionStream();
        }
      } else {
        soundCounter = 0;
        silenceCounter++;

        // é€£çºŒéœéŸ³ä¸€æ®µæ™‚é–“å¾Œåœæ­¢è½‰éŒ„ä¸²æµ
        if (silenceCounter > silenceThreshold && this.isTranscribeStreamActive) {
          console.log("ğŸ¤« æŒçºŒéœéŸ³ - åœæ­¢è½‰éŒ„ä¸²æµ");
          this.stopTranscriptionStream();
          this.clearTranscription();
        }
      }

      requestAnimationFrame(detectSound);
    };

    detectSound();
  }

  /**
   * åˆå§‹åŒ– Kinesis Video Client
   * @param cfg
   * @returns
   */
  private createKinesisVideoClient(cfg: AwsConfig): KinesisVideoClient {
    return new KinesisVideoClient({
      region: cfg.region,
      credentials: {
        accessKeyId: cfg.accessKeyId,
        secretAccessKey: cfg.secretAccessKey,
        sessionToken: cfg.sessionToken,
      },
    });
  }

  /**
   * åˆå§‹åŒ– Signaling Client
   * æ³¨æ„ï¼šKVSWebRTC.SignalingClient ä¾†è‡ª windowï¼Œå‹åˆ¥éœ€ç”¨ any æˆ–è‡ªè¨‚
   * @param cfg
   * @param wssEndpoint
   * @param role
   * @param clientId
   * @returns
   */
  private createSignalingClient(cfg: AwsConfig, wssEndpoint: string, role: Role, clientId?: string): any {
    return new KVSWebRTC.SignalingClient({
      channelARN: cfg.channelARN,
      channelEndpoint: wssEndpoint,
      role,
      clientId,
      region: cfg.region,
      credentials: {
        accessKeyId: cfg.accessKeyId,
        secretAccessKey: cfg.secretAccessKey,
        sessionToken: cfg.sessionToken
      },
      systemClockOffset: 0,
    });
  }

  /**
   * å–å¾— ICE Servers
   * @param cfg
   * @param httpsEndpoint
   * @returns
   */
  private async getIceServers(cfg: AwsConfig, httpsEndpoint: string): Promise<RTCIceServer[]> {
    const kinesisVideoSignalingClient = new KinesisVideoSignalingClient({
      region: cfg.region,
      credentials: {
        accessKeyId: cfg.accessKeyId,
        secretAccessKey: cfg.secretAccessKey,
        sessionToken: cfg.sessionToken,
      },
      endpoint: httpsEndpoint,
    });
    const command = new GetIceServerConfigCommand({ ChannelARN: cfg.channelARN });
    const response = await kinesisVideoSignalingClient.send(command);
    const iceServers: RTCIceServer[] = [{ urls: `stun:stun.kinesisvideo.${cfg.region}.amazonaws.com:443` }];
    response.IceServerList?.forEach(iceServer =>
      iceServers.push({
        urls: iceServer.Uris as string[] | string,
        username: iceServer.Username,
        credential: iceServer.Password,
      })
    );
    return iceServers;
  }

  /**
   * å–å¾— signaling channel endpoint
   * @param cfg
   * @param role
   * @returns
   */
  private async getSignalingChannelEndpoint(cfg: AwsConfig, role: Role) {
    const client = this.createKinesisVideoClient(cfg);
    const command = new GetSignalingChannelEndpointCommand({
      ChannelARN: cfg.channelARN,
      SingleMasterChannelEndpointConfiguration: {
        Protocols: ['WSS', 'HTTPS'],
        Role: role,
      },
    });
    return await client.send(command);
  }

  /**
   * Viewer ç«¯é»æ“Šé–‹å§‹é€£ç·š
   */
  async onclickViewer() {
    this.mode = 'viewer';
    const cfg = await this.getAwsConfig();
    const clientId = Math.floor(Math.random() * 999999).toString();

    const endpoints = await this.getSignalingChannelEndpoint(cfg, Role.VIEWER);
    const httpsEndpoint = endpoints.ResourceEndpointList?.find(x => x.Protocol === 'HTTPS')?.ResourceEndpoint ?? '';
    const wssEndpoint = endpoints.ResourceEndpointList?.find(x => x.Protocol === 'WSS')?.ResourceEndpoint ?? '';
    const iceServers = await this.getIceServers(cfg, httpsEndpoint);
    const peerConnection = new RTCPeerConnection({ iceServers });
    const signalingClient = this.createSignalingClient(cfg, wssEndpoint, Role.VIEWER, clientId);

    signalingClient.on('open', async () => {
      const viewerStream = await navigator.mediaDevices.getUserMedia({
        video: { width: { ideal: 1280 }, height: { ideal: 720 } },
        audio: true,
      });

      this.localView.nativeElement.srcObject = viewerStream;
      this.localStream = viewerStream;

      viewerStream.getTracks().forEach(track => peerConnection.addTrack(track, viewerStream));
      await peerConnection.setLocalDescription(await peerConnection.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: true }));
      signalingClient.sendSdpOffer(peerConnection.localDescription as RTCSessionDescription);
    });
    signalingClient.on('sdpAnswer', async answer => {
      await peerConnection.setRemoteDescription(answer);
      // RTC é€£ç·šå®Œæˆå¾Œè‡ªå‹•å•Ÿå‹•è½‰éŒ„
      console.log('Viewer: RTC é€£ç·šå®Œæˆï¼Œå•Ÿå‹•è½‰éŒ„ç³»çµ±');
      await this.startTranscription();
    });
    signalingClient.on('iceCandidate', candidate => {
      peerConnection.addIceCandidate(candidate);
    });
    signalingClient.on('close', () => { });
    signalingClient.on('error', error => { console.log('error', error); });
    peerConnection.addEventListener('icecandidate', ({ candidate }) => {
      if (candidate) signalingClient.sendIceCandidate(candidate);
    });
    peerConnection.addEventListener('track', event => {
      this.remoteView.nativeElement.srcObject = event.streams[0];
      this.remoteStream = event.streams[0];

      this.updateTranscribeStream();
    });
    signalingClient.open();
  }

  /**
   * Master ç«¯é»æ“Šé–‹å§‹é€£ç·š
   */
  async onclickMaster() {
    this.mode = 'master';
    const cfg = await this.getAwsConfig();
    let remoteId = '';
    const endpoints = await this.getSignalingChannelEndpoint(cfg, Role.MASTER);
    const httpsEndpoint = endpoints.ResourceEndpointList?.find(x => x.Protocol === 'HTTPS')?.ResourceEndpoint ?? '';
    const wssEndpoint = endpoints.ResourceEndpointList?.find(x => x.Protocol === 'WSS')?.ResourceEndpoint ?? '';
    const iceServers = await this.getIceServers(cfg, httpsEndpoint);
    const peerConnection = new RTCPeerConnection({ iceServers, iceTransportPolicy: 'all' });
    const signalingClient = this.createSignalingClient(cfg, wssEndpoint, Role.MASTER);

    signalingClient.on('open', async () => {
      this.localStream = await navigator.mediaDevices.getUserMedia({
        video: { width: { ideal: 1280 }, height: { ideal: 720 } },
        audio: true,
      });
      this.localView.nativeElement.srcObject = this.localStream;
      this.localStream.getTracks().forEach(track => peerConnection.addTrack(track, this.localStream));
    });
    signalingClient.on('sdpOffer', async (offer, remoteClientId) => {
      remoteId = remoteClientId;
      await peerConnection.setRemoteDescription(offer);
      await peerConnection.setLocalDescription(await peerConnection.createAnswer({ offerToReceiveAudio: true, offerToReceiveVideo: true }));
      signalingClient.sendSdpAnswer(peerConnection.localDescription as RTCSessionDescription, remoteId);
      // RTC é€£ç·šå®Œæˆå¾Œè‡ªå‹•å•Ÿå‹•è½‰éŒ„
      console.log('Master: RTC é€£ç·šå®Œæˆï¼Œå•Ÿå‹•è½‰éŒ„ç³»çµ±');
      await this.startTranscription();
    });
    signalingClient.on('iceCandidate', candidate => {
      peerConnection.addIceCandidate(candidate);
    });
    signalingClient.on('close', () => { });
    signalingClient.on('error', error => { console.log('error', error); });
    peerConnection.addEventListener('icecandidate', ({ candidate }) => {
      if (candidate) signalingClient.sendIceCandidate(candidate, remoteId);
    });
    peerConnection.addEventListener('track', event => {
      this.remoteView.nativeElement.srcObject = event.streams[0];
      this.remoteStream = event.streams[0];

      // ç•¶é ç«¯éŸ³è¨Šå¯ç”¨æ™‚ï¼Œæ›´æ–°è½‰éŒ„æµ
      this.updateTranscribeStream();
    });
    signalingClient.open();
  }

  /**
   * éŒ„éŸ³æµç¨‹
   * æ³¨æ„ï¼šæ­¤æ–¹æ³•æœƒä½¿ç”¨ AudioContext ä¾†è™•ç†éŸ³è¨Šæµï¼Œä¸¦å°‡æœ¬åœ°å’Œé ç«¯éŸ³è¨Šæµåˆä½µå¾Œé€²è¡ŒéŒ„éŸ³ã€‚
   * @returns
   */
  async startRecording() {
    this.isRecording = true;
    if (!this.localStream) {
      console.error('Local stream is not available for recording.');
      return;
    }
    const audioContext = new AudioContext();
    const destination = audioContext.createMediaStreamDestination();
    const localSource = audioContext.createMediaStreamSource(this.localStream);
    localSource.connect(destination);
    if (this.remoteStream && this.remoteStream.getAudioTracks().length > 0) {
      const remoteSource = audioContext.createMediaStreamSource(this.remoteStream);
      remoteSource.connect(destination);
    }
    const combinedStream = destination.stream;
    this.mediaRecorder = new MediaRecorder(combinedStream, { mimeType: 'audio/webm' });
    this.recordedChunks = [];
    this.mediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) this.recordedChunks.push(e.data);
    };
    this.mediaRecorder.onstop = async () => {
      const fileName = `recording-${new Date().toISOString().replace(/[-:T]/g, '').slice(0, 14)}.webm`;
      const blob = new Blob(this.recordedChunks, { type: 'audio/webm' });
      this.downloadBlob(blob, fileName);
      await this.uploadToS3(blob, fileName);
    };
    this.mediaRecorder.start();
  }

  /**
   * åœæ­¢éŒ„éŸ³
   */
  stopRecording() {
    this.isRecording = false;
    this.mediaRecorder?.stop();
  }

  /**
   * ä¸‹è¼‰ Blobï¼Œæ¸¬è©¦ç”¨
   * @param blob
   * @param fileName
   */
  private downloadBlob(blob: Blob, fileName: string) {
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = fileName;
    a.click();
  }

  /**
   * å°‡éŸ³è¨Šä¸Šå‚³åˆ° S3
   * @param blob
   * @param fileName
   */
  private async uploadToS3(blob: Blob, fileName: string) {
    this.isUploading = true;
    const cfg = await this.getAwsConfig();
    const client = new S3Client({
      region: cfg.region,
      credentials: {
        accessKeyId: cfg.accessKeyId,
        secretAccessKey: cfg.secretAccessKey,
        sessionToken: cfg.sessionToken,
      },
      forcePathStyle: true,
      requestHandler: { requestTimeout: 0, httpsAgent: undefined }
    });
    const arrayBuffer = await blob.arrayBuffer();
    const uint8Array = new Uint8Array(arrayBuffer);
    const bucketName = environment.audioBucketName;
    const putCommand = new PutObjectCommand({
      Bucket: bucketName,
      Key: fileName,
      Body: uint8Array,
      ContentType: 'audio/webm',
    });
    try {
      const result = await client.send(putCommand);
      console.log('Successfully uploaded to S3:', result);
    } catch (caught) {
      console.error('Upload failed:', caught);
      console.log('Falling back to local download only');
    } finally {
      this.isUploading = false;
    }
  }

  /**
 * åˆ‡æ›èŠå¤©å®¤é¡¯ç¤ºç‹€æ…‹
 */
  toggleChat() {
    this.isChatOpen = !this.isChatOpen;
  }

  /**
   * ç™¼é€èŠå¤©è¨Šæ¯
   */
  async sendMessage() {
    if (!this.currentMessage.trim() || this.isLoadingMessage) return;

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      text: this.currentMessage,
      isUser: true,
      timestamp: new Date()
    };

    this.chatMessages.push(userMessage);
    const messageToSend = this.currentMessage;
    this.currentMessage = '';
    this.isLoadingMessage = true;

    try {
      // èª¿ç”¨ API Gateway èŠå¤© API
      const response = await this.http.post(environment.chatUrl, {
        Message: messageToSend,
        SessionId: this.sessionId
      }, {
        responseType: 'text'
      }).toPromise();

      const aiMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        text: response || 'æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚ç„¡æ³•å›æ‡‰ã€‚',
        isUser: false,
        timestamp: new Date()
      };

      this.chatMessages.push(aiMessage);
    } catch (error) {
      console.error('ç™¼é€è¨Šæ¯å¤±æ•—:', error);
      const errorMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        text: 'æŠ±æ­‰ï¼Œç™¼é€è¨Šæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚',
        isUser: false,
        timestamp: new Date()
      };
      this.chatMessages.push(errorMessage);
    } finally {
      this.isLoadingMessage = false;
      setTimeout(() => this.scrollToBottom(), 100);
    }
  }

  /**
   * è™•ç† Enter éµç™¼é€è¨Šæ¯
   */
  onKeyPress(event: KeyboardEvent) {
    if (event.isComposing || event.keyCode === 229) {
      return;
    }

    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault();
      this.sendMessage();
      this.scrollToBottom();
    }
  }

  /**
   * æ»¾å‹•èŠå¤©å®¤åˆ°åº•éƒ¨
   */
  private scrollToBottom() {
    const chatContainer = document.querySelector('.chat-messages');
    if (chatContainer) {
      chatContainer.scrollTop = chatContainer.scrollHeight;
    }
  }

  /**
   * æ¸…é™¤èŠå¤©è¨˜éŒ„
   */
  clearChat() {
    this.chatMessages = [];
    this.sessionId = this.generateSessionId();
  }
}
